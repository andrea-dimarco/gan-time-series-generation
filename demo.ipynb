{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series Generation using Contrastive Learning\n",
    "\n",
    "Consider learning a generative model for time-series data.\n",
    "\n",
    "The sequential setting poses a unique challenge: Not only should the generator capture the conditional dynamics of (stepwise) transitions, but its open-loop rollouts should also preserve the joint distribution of (multi-step) trajectories.\n",
    "\n",
    "On one hand, autoregressive models\n",
    "trained by MLE allow learning and computing explicit transition distributions, but suffer from compounding error during rollouts.\n",
    "\n",
    "On the other hand, adversarial models based on GAN training alleviate such exposure bias, but transitions are implicit and hard to assess.\n",
    "\n",
    "In this work, we study a generative framework that seeks to combine the strengths of both: Motivated by a moment-matching objective to mitigate\n",
    "compounding error, we optimize a local (but forward-looking) *transition policy*, where the reinforcement signal is provided by a global (but stepwise-decomposable) *energy model* trained by contrastive estimation. \n",
    "\n",
    "At **training**, the two components are learned cooperatively, avoiding the instabilities typical of adversarial objectives. \n",
    "\n",
    "At **inference**, the learned policy serves as the generator for iterative sampling, and the learned energy serves as a trajectory-level measure for evaluating sample quality.\n",
    "\n",
    "By expressly training a policy to imitate sequential behavior of time-series features in a dataset, this approach embodies *“generation by imitation”*. Theoretically, we illustrate the correctness of this formulation and the consistency of the algorithm.\n",
    "\n",
    "Empirically, we evaluate its ability to generate predictively useful samples from real-world datasets, verifying that it performs at the standard of existing benchmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Install libraries\n",
    "\n",
    "Run the cell below to **install** the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wandb\n",
    "%pip install pytorch-lightning\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change or remove these commands with the right ones for your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install cuda-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import Libraries\n",
    "\n",
    "Run the cell below to **import** the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning import Trainer\n",
    "# from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eh eh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Hyper-parameters\n",
    "\n",
    "The cell below contains *all* the hyper-parameters nedded by this script, for easy tweaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperparamets import Config\n",
    "hparams = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment this cell if you don't want to use Weights & Biases to log the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Initialization\n",
    "\n",
    "Initialize the modules needed by running the cells in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.1 reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True # Can have performance impact\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "_ = pl.seed_everything(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.2 Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.3 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the dataset as requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from hyperparamets import Config\n",
    "print(os.listdir('.'))\n",
    "hparams = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to the folder containing the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_folder = hparams.dataset_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generation import iid_sequence_generator, sine_process, wiener_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hparams.dataset_name in ['sine', 'wien', 'iid', 'cov']:\n",
    "  # Generate and store the dataset as requested\n",
    "  dataset_path = f\"../datasets/{hparams.dataset_name}_generated_stream.csv\"\n",
    "  if hparams.dataset_name == 'sine':\n",
    "    sine_process.save_sine_process(p=hparams.data_dim, N=hparams.num_samples, file_path=dataset_path)\n",
    "  elif hparams.dataset_name == 'wien':\n",
    "    wiener_process.save_wiener_process(p=hparams.data_dim, N=hparams.num_samples, file_path=dataset_path)\n",
    "  elif hparams.dataset_name == 'iid':\n",
    "    iid_sequence_generator.save_iid_sequence(p=hparams.data_dim, N=hparams.num_samples, file_path=dataset_path)\n",
    "  elif hparams.dataset_name == 'cov':\n",
    "    iid_sequence_generator.save_cov_sequence(p=hparams.data_dim, N=hparams.num_samples, file_path=dataset_path)\n",
    "  else:\n",
    "    raise ValueError\n",
    "  print(f\"The {hparams.dataset_name} dataset has been succesfully created and stored into:\\n\\t- {dataset_path}\")\n",
    "elif hparams.dataset_name == 'real':\n",
    "  pass\n",
    "else:\n",
    "  raise ValueError(\"Dataset not supported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_handling import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hparams.dataset_name in ['sine', 'wien', 'iid', 'cov']:\n",
    "    train_dataset_path = f\"{datasets_folder}{hparams.dataset_name}_training.csv\"\n",
    "    test_dataset_path = f\"{datasets_folder}{hparams.dataset_name}_testing.csv\"\n",
    "    val_dataset_path  = f\"{datasets_folder}{hparams.dataset_name}_validating.csv\"\n",
    "\n",
    "    # Train & Test\n",
    "    train_test_split(X=np.loadtxt(dataset_path, delimiter=\",\", dtype=np.float32),\n",
    "                    split=hparams.train_test_split,\n",
    "                    train_file_name=train_dataset_path,\n",
    "                    test_file_name=test_dataset_path    \n",
    "                    )\n",
    "\n",
    "    # Train & Validation\n",
    "    train_test_split(X=np.loadtxt(train_dataset_path, delimiter=\",\", dtype=np.float32),\n",
    "                    split=hparams.train_val_split,\n",
    "                    train_file_name=train_dataset_path,\n",
    "                    test_file_name=val_dataset_path    \n",
    "                    )\n",
    "    \n",
    "    print(f\"The {hparams.dataset_name} dataset has been split successfully into:\\n\\t- {train_dataset_path}\\n\\t- {val_dataset_path}\")\n",
    "elif hparams.dataset_name == 'real':\n",
    "    train_dataset_path = datasets_folder + hparams.train_file_name\n",
    "    test_dataset_path  = datasets_folder + hparams.test_file_name\n",
    "    val_dataset_path   = datasets_folder + hparams.val_file_name\n",
    "else:\n",
    "  raise ValueError(\"Dataset not supported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell loads the TimeGAN model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timegan_model import TimeGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Train\n",
    "\n",
    "This chapter will train the model according to the hyper-parameters defined above in section [Hyper-parameters](#13-hyper-parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "timegan = TimeGAN(hparams=hparams,\n",
    "                    train_file_path=train_dataset_path,\n",
    "                    val_file_path=val_dataset_path\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logger -> https://www.wandb.com/articles/pytorch-lightning-with-weights-biases.\n",
    "wandb_logger = WandbLogger(project=\"TimeGAN PyTorch (2024)\", log_model=True)\n",
    "wandb_logger.experiment.watch(timegan, log='all', log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the trainer\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    patience=hparams.early_stop_patience,\n",
    "    strict=False,\n",
    "    verbose=False\n",
    ")\n",
    "trainer = Trainer(logger=wandb_logger,\n",
    "                max_epochs=hparams.n_epochs,\n",
    "                val_check_interval=0.10,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training\n",
    "trainer.fit(timegan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the trained model\n",
    "trainer.save_checkpoint('timegan.pth')\n",
    "wandb.save('timegan.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Linear Deterministic Anomaly Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these tests the model will be asked to generate sequences that a deterministic PCA-based anomaly detector will scan looking for irregularities with respect to the real sequences.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the anomaly detection deterministic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anomaly_detection import anomaly_detector_api as AD_API\n",
    "import dataset_handling as dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the test dataset and precompute the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dh.RealDataset(\n",
    "                file_path=test_dataset_path,\n",
    "                seq_len=hparams.seq_len\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAR_tot = 0.0 # False Alarm Rate (on nominal data)\n",
    "TAR_tot = 0.0 # True Alarm Rate (on synthetic data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working folder and file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_folder = \"./src/anomaly_detection/\"\n",
    "AD_offline_path = f\"{datasets_folder}{hparams.dataset_name}_testing_AD_offline.csv\"\n",
    "AD_online_path  = f\"{datasets_folder}{hparams.dataset_name}_testing_AD_online.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model is trained on normalized data, we must train the AD on normalized data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hparams.operating_system != 'windows':\n",
    "    df = pd.DataFrame( np.transpose(test_dataset.get_whole_stream().numpy()) )\n",
    "    df.to_csv(AD_offline_path, index=False, header=False)\n",
    "\n",
    "    # train AD\n",
    "    AD_API.pca_offline(AD_offline_path, folder=AD_folder)\n",
    "else:\n",
    "    print(\"The PCA-based Anomaly Detector related tests are not currently supported for this operating system.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly rate on the real data, thus the AD's false alarm rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hparams.operating_system != 'windows':\n",
    "    anomalies_found = AD_API.pca_online(file_path=AD_offline_path, folder=AD_folder, h=hparams.h, alpha=hparams.alpha)\n",
    "    FAR_tot += anomalies_found\n",
    "\n",
    "    # free memory\n",
    "    os.system(f\"rm {AD_offline_path}\")\n",
    "else:\n",
    "    print(\"The PCA-based Anomaly Detector related tests are not currently supported for this operating system.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run tests on generated sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hparams.operating_system != 'windows':\n",
    "    for idx, (X, Z) in enumerate(test_dataset):\n",
    "        # Get the synthetic sequence\n",
    "        Z_seq = Z.reshape(1, hparams.seq_len, hparams.noise_dim)\n",
    "        X_seq = timegan(Z_seq).detach().reshape(hparams.seq_len, hparams.data_dim)\n",
    "\n",
    "        # save synthetic sequence to a file\n",
    "        X_seq = np.transpose(X_seq.numpy())\n",
    "        df = pd.DataFrame(X_seq)\n",
    "        df.to_csv(AD_online_path, index=False, header=False)\n",
    "\n",
    "        # run simulation\n",
    "        anomalies_found = AD_API.pca_online(file_path=AD_online_path, folder=AD_folder, h=hparams.h, alpha=hparams.alpha)\n",
    "        TAR_tot += anomalies_found\n",
    "    TAR_tot /= len(test_dataset)\n",
    "\n",
    "    # free memory\n",
    "    os.system(f\"rm {AD_online_path}\")\n",
    "    AD_API.cleanup_files()\n",
    "\n",
    "else:\n",
    "    print(\"The PCA-based Anomaly Detector related tests are not currently supported for this operating system.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Anomalies found on real data: {round(FAR_tot*100, 2)}%\")\n",
    "print(f\"Anomalies found on fake data: {round(TAR_tot*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Other Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
