{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series Generation using Contrastive Learning\n",
    "\n",
    "Consider learning a generative model for time-series data.\n",
    "\n",
    "The sequential setting poses a unique challenge: Not only should the generator capture the conditional dynamics of (stepwise) transitions, but its open-loop rollouts should also preserve the joint distribution of (multi-step) trajectories.\n",
    "\n",
    "On one hand, autoregressive models\n",
    "trained by MLE allow learning and computing explicit transition distributions, but suffer from compounding error during rollouts.\n",
    "\n",
    "On the other hand, adversarial models based on GAN training alleviate such exposure bias, but transitions are implicit and hard to assess.\n",
    "\n",
    "In this work, we study a generative framework that seeks to combine the strengths of both: Motivated by a moment-matching objective to mitigate\n",
    "compounding error, we optimize a local (but forward-looking) *transition policy*, where the reinforcement signal is provided by a global (but stepwise-decomposable) *energy model* trained by contrastive estimation. \n",
    "\n",
    "At **training**, the two components are learned cooperatively, avoiding the instabilities typical of adversarial objectives. \n",
    "\n",
    "At **inference**, the learned policy serves as the generator for iterative sampling, and the learned energy serves as a trajectory-level measure for evaluating sample quality.\n",
    "\n",
    "By expressly training a policy to imitate sequential behavior of time-series features in a dataset, this approach embodies *“generation by imitation”*. Theoretically, we illustrate the correctness of this formulation and the consistency of the algorithm.\n",
    "\n",
    "Empirically, we evaluate its ability to generate predictively useful samples from real-world datasets, verifying that it performs at the standard of existing benchmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Install libraries\n",
    "\n",
    "Run the cell below to **install** the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wandb\n",
    "%pip install pytorch-lightning\n",
    "%pip install plotly\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Import Libraries\n",
    "\n",
    "Run the cell below to **import** the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning import Trainer\n",
    "# from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pytorch_lightning.loggers.wandb import WandbLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eh eh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Hyper-parameters\n",
    "\n",
    "The cell below contains *all* the hyper-parameters nedded by this script, for easy tweaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperparamets import Config\n",
    "hparams = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment this cell if you don't want to use Weights & Biases to log the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Initialization\n",
    "\n",
    "Initialize the modules needed by running the cells in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.1 reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True # Can have performance impact\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "_ = pl.seed_everything(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.2 Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.3 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the dataset as requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from hyperparamets import Config\n",
    "print(os.listdir('.'))\n",
    "hparams = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generation import iid_sequence_generator, sine_process, wiener_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hparams.dataset_name in ['sine', 'wien', 'iid', 'cov']:\n",
    "  # Generate and store the dataset as requested\n",
    "  dataset_path = f\"../datasets/{hparams.dataset_name}_generated_stream.csv\"\n",
    "  if hparams.dataset_name == 'sine':\n",
    "    sine_process.save_sine_process(p=hparams.data_dim, N=hparams.num_samples, file_path=dataset_path)\n",
    "  elif hparams.dataset_name == 'wien':\n",
    "    wiener_process.save_wiener_process(p=hparams.data_dim, N=hparams.num_samples, file_path=dataset_path)\n",
    "    print(\"\\n\")\n",
    "  elif hparams.dataset_name == 'iid':\n",
    "    iid_sequence_generator.save_iid_sequence(p=hparams.data_dim, N=hparams.num_samples, file_path=dataset_path)\n",
    "  elif hparams.dataset_name == 'cov':\n",
    "    iid_sequence_generator.save_cov_sequence(p=hparams.data_dim, N=hparams.num_samples, file_path=dataset_path)\n",
    "  else:\n",
    "    raise ValueError\n",
    "  print(f\"The {hparams.dataset_name} dataset has been succesfully created and stored into:\\n\\t- {dataset_path}\")\n",
    "elif hparams.dataset_name == 'real':\n",
    "  pass\n",
    "else:\n",
    "  raise ValueError(\"Dataset not supported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_handling import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hparams.dataset_name in ['sine', 'wien', 'iid', 'cov']:\n",
    "    train_dataset_path = f\"../datasets/{hparams.dataset_name}_training.csv\"\n",
    "    test_dataset_path  = f\"../datasets/{hparams.dataset_name}_testing.csv\"\n",
    "\n",
    "    train_test_split(X=np.loadtxt(dataset_path, delimiter=\",\", dtype=np.float32),\n",
    "                    split=hparams.train_test_split,\n",
    "                    train_file_name=train_dataset_path,\n",
    "                    test_file_name=test_dataset_path    \n",
    "                    )\n",
    "    \n",
    "    print(f\"The {hparams.dataset_name} dataset has been split successfully into:\\n\\t- {train_dataset_path}\\n\\t- {test_dataset_path}\")\n",
    "elif hparams.dataset_name == 'real':\n",
    "    train_dataset_path = hparams.train_file_path\n",
    "    test_dataset_path  = hparams.test_file_path\n",
    "else:\n",
    "  raise ValueError(\"Dataset not supported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell loads the TimeGAN model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timegan_model import TimeGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Train\n",
    "\n",
    "This chapter will train the model according to the hyper-parameters defined above in section [Hyper-parameters](#13-hyper-parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "timegan = TimeGAN(hparams=hparams,\n",
    "                    train_file_path=train_dataset_path,\n",
    "                    test_file_path=test_dataset_path\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logger -> https://www.wandb.com/articles/pytorch-lightning-with-weights-biases.\n",
    "wandb_logger = WandbLogger(project=\"TimeGAN PyTorch (2024)\", log_model=True)\n",
    "wandb_logger.experiment.watch(timegan, log='all', log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the trainer\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    patience=hparams.early_stop_patience,\n",
    "    strict=False,\n",
    "    verbose=False\n",
    ")\n",
    "trainer = Trainer(logger=wandb_logger,\n",
    "                max_epochs=hparams.n_epochs,\n",
    "                accelerator=accelerator,\n",
    "                val_check_interval=0.25,\n",
    "                callbacks=[early_stop]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training\n",
    "trainer.fit(timegan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the trained model\n",
    "trainer.save_checkpoint('timegan.pth')\n",
    "wandb.save('timegan.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
